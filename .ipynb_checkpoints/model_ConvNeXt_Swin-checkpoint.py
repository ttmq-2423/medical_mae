import torch
import torch.nn as nn
from timm.models.swin_transformer import SwinTransformer
from timm.models.convnext import ConvNeXt

class ConvNeXt_Swin(nn.Module):
    def __init__(self, num_classes=5):
        super().__init__()

        # Stage 1, 2, 3: ConvNeXt Blocks
        self.convnext = ConvNeXt(
            depths=(3, 3, 27, 3),  
            dims=(96, 192, 384, 768)  
        )

        # ğŸ”§ Chuyá»ƒn Ä‘á»•i sá»‘ kÃªnh tá»« 384 â 3 Ä‘á»ƒ phÃ¹ há»£p vá»›i Swin Transformer
        self.channel_reduction = nn.Conv2d(384, 3, kernel_size=1, stride=1, padding=0)

        # Stage 4: Swin Transformer
        self.swin_stage4 = SwinTransformer(
            img_size=7,   
            embed_dim=3,  # ğŸ”§ Äá»ƒ khá»›p vá»›i sá»‘ kÃªnh Ä‘áº§u vÃ o
            depths=[3],    
            num_heads=[3]  
        )

        # Global Pooling & Fully Connected Layer
        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  
        self.fc = nn.Linear(3, num_classes)  # ğŸ”§ Äáº§u vÃ o FC pháº£i khá»›p vá»›i embed_dim

    def forward(self, x):
        x = self.convnext.stem(x)  
        x = self.convnext.stages[0](x)  
        x = self.convnext.stages[1](x)  
        x = self.convnext.stages[2](x)  

        print("Shape before Swin Transformer:", x.shape)  # Debug shape

        x = torch.nn.functional.adaptive_avg_pool2d(x, (7, 7))  # âœ… Chuáº©n hÃ³a kÃ­ch thÆ°á»›c
        x = self.channel_reduction(x)  # âœ… Chuyá»ƒn tá»« 384 â†’ 3 kÃªnh
        x = self.swin_stage4(x)  

        print("Shape before Global Pooling:", x.shape)  # Debug shape

        x = self.global_pool(x)
        x = x.view(x.shape[0], -1)  

        print("Shape before FC:", x.shape)  # Debug shape

        x = self.fc(x)  
        return x
